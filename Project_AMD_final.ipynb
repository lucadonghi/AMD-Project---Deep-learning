{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Convolutional Neural Network** \n",
        "# **Binary classification of face images: comics or real?**\n",
        "\n",
        "**Task**: to implement a deep-learning-based system discriminating between real faces and comics, using the «Comics faces» kaggle dataset\n",
        "\n",
        "**Dataset**: The «[Comic faces](https://https://www.kaggle.com/datasets/defileroff/comic-faces-paired-synthetic-v2)» dataset is published on Kaggle and released under the CC-BY 4.0 license, with attribution required. It contains 10.000 real faces images and 10.000 comics faces images in 1024x1024 format.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CIt-oMao4yPo"
      },
      "id": "CIt-oMao4yPo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Importing the required libraries**"
      ],
      "metadata": {
        "id": "IoMhB3Vp8JdL"
      },
      "id": "IoMhB3Vp8JdL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c2ff757",
      "metadata": {
        "id": "7c2ff757"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import sklearn\n",
        "import seaborn as sn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command will allow us to display the **tensorboard inline** in this Google Colab Notebook"
      ],
      "metadata": {
        "id": "W_8Sgnxu4gFu"
      },
      "id": "W_8Sgnxu4gFu"
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "aAOQczgPH2y3"
      },
      "id": "aAOQczgPH2y3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) Loading the Dataset**"
      ],
      "metadata": {
        "id": "6OtRlsD69Ky6"
      },
      "id": "6OtRlsD69Ky6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell code is needed for **Kaggle API authentication**.\n",
        "You have to upload your kaggle.json authentication token."
      ],
      "metadata": {
        "id": "NugfwPmX4_3c"
      },
      "id": "NugfwPmX4_3c"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "b23mTiMs6bdg"
      },
      "id": "b23mTiMs6bdg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the command for **Kaggle API installation** and authentication."
      ],
      "metadata": {
        "id": "vx0o1kM99eU9"
      },
      "id": "vx0o1kM99eU9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197cc345",
      "metadata": {
        "id": "197cc345"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "import kaggle\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can **download the dataset** and unzip it."
      ],
      "metadata": {
        "id": "SRe860Gs9u6V"
      },
      "id": "SRe860Gs9u6V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b75a453c",
      "metadata": {
        "id": "b75a453c"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d defileroff/comic-faces-paired-synthetic-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3895e7f2",
      "metadata": {
        "id": "3895e7f2"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('comic-faces-paired-synthetic-v2.zip','r') as zipref:\n",
        "     zipref.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the next line we eliminate the folder containing not useful images.\n",
        "Keeping only the two folders with real faces and comic faces will simplify the code."
      ],
      "metadata": {
        "id": "N1XmR62zDn7k"
      },
      "id": "N1XmR62zDn7k"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela/samples"
      ],
      "metadata": {
        "id": "V-XfmgUWebua"
      },
      "id": "V-XfmgUWebua",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's display our data!"
      ],
      "metadata": {
        "id": "l5VWtk2d-gAj"
      },
      "id": "l5VWtk2d-gAj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e913a7c",
      "metadata": {
        "id": "0e913a7c"
      },
      "outputs": [],
      "source": [
        "DATADIR = \"/content/face2comics_v2.0.0_by_Sxela/face2comics_v2.0.0_by_Sxela\"\n",
        "\n",
        "CATEGORIES = [\"faces\", \"comics\"]\n",
        "\n",
        "\n",
        "for category in CATEGORIES:  \n",
        "    path = os.path.join(DATADIR,category)  \n",
        "    for img in os.listdir(path):  \n",
        "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  \n",
        "        plt.imshow(img_array, cmap='gray')  \n",
        "        plt.show()  \n",
        "\n",
        "        break  \n",
        "    break  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d00129",
      "metadata": {
        "id": "a6d00129"
      },
      "outputs": [],
      "source": [
        "print(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52c19ae",
      "metadata": {
        "id": "c52c19ae"
      },
      "outputs": [],
      "source": [
        "print(img_array.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3) Preprocessing the images**\n",
        "In this section I'm reshaping and putting in **gray scale** the images.\n",
        "**150x150** seems to be a reasonable size in order to still recognize the content and save some storage, computational and time capacity.\n",
        "The gray scale has been applied for the same purpous."
      ],
      "metadata": {
        "id": "rK-Qpp22_Zxg"
      },
      "id": "rK-Qpp22_Zxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c3520ca",
      "metadata": {
        "id": "7c3520ca"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 150\n",
        "\n",
        "new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "plt.imshow(new_array, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I created the **complete labeled dataset**"
      ],
      "metadata": {
        "id": "JxCsK9U_CbGS"
      },
      "id": "JxCsK9U_CbGS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3649c755",
      "metadata": {
        "id": "3649c755"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "\n",
        "def create_all_data():\n",
        "    for category in CATEGORIES:  \n",
        "\n",
        "        path = os.path.join(DATADIR,category)  \n",
        "        class_num = CATEGORIES.index(category)  \n",
        "\n",
        "        for img in os.listdir(path):  \n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  \n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  \n",
        "                all_data.append([new_array, class_num])  \n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "\n",
        "create_all_data()\n",
        "\n",
        "print(len(all_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Shuffling** the data is needed. Keeping them sequentially would likely lead our classifier to perform bad. It would learn always to predict a label and at a certain point to switch."
      ],
      "metadata": {
        "id": "NYBv2_KBCvYf"
      },
      "id": "NYBv2_KBCvYf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c0f0ced",
      "metadata": {
        "id": "4c0f0ced"
      },
      "outputs": [],
      "source": [
        "random.shuffle(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e078052",
      "metadata": {
        "id": "8e078052"
      },
      "outputs": [],
      "source": [
        "for sample in all_data[:10]:\n",
        "    print(sample[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separating images from labels. "
      ],
      "metadata": {
        "id": "o1-kM9KBDSEn"
      },
      "id": "o1-kM9KBDSEn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46eac52",
      "metadata": {
        "id": "a46eac52"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "\n",
        "y = []\n",
        "\n",
        "for features,label in all_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1)) #if I use colours instead of gray scale, I have to change from 1 to 3\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) #if I use colours instead of gray scale, I have to change from 1 to 3\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling** the images such that their pixel values are normalized between 0 and 1 will make the work a lot easier for the CNN"
      ],
      "metadata": {
        "id": "XWhrdXju76kg"
      },
      "id": "XWhrdXju76kg"
    },
    {
      "cell_type": "code",
      "source": [
        "x = X/255.0 "
      ],
      "metadata": {
        "id": "DigMA0WG7scj"
      },
      "id": "DigMA0WG7scj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4) Training set and Test set**\n",
        "I randomly sampled a portion of the complete dataset to keep away in order to perform the the final test of my trained classifiers. "
      ],
      "metadata": {
        "id": "DN3TZjF6Dj4c"
      },
      "id": "DN3TZjF6Dj4c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb32da7",
      "metadata": {
        "id": "2fb32da7"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0792f05a",
      "metadata": {
        "id": "0792f05a"
      },
      "outputs": [],
      "source": [
        "x_test[1:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8051c7f",
      "metadata": {
        "id": "e8051c7f"
      },
      "outputs": [],
      "source": [
        "type(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5ea785",
      "metadata": {
        "id": "fd5ea785"
      },
      "outputs": [],
      "source": [
        "type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a405ce0",
      "metadata": {
        "id": "7a405ce0"
      },
      "outputs": [],
      "source": [
        "print(len(x_train))\n",
        "print(len(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5) First round of model selection**\n",
        "In this section I used only a small portion of the training set (**4.800 images**) in order to compare the performanceas of a large number of models."
      ],
      "metadata": {
        "id": "xNeGNr5lFQV4"
      },
      "id": "xNeGNr5lFQV4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57ef39c6",
      "metadata": {
        "id": "57ef39c6"
      },
      "outputs": [],
      "source": [
        "x_train_try1, x_train_notused1, y_train_try1, y_train_notused1 = train_test_split(x_train,y_train,test_size=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c80e4519",
      "metadata": {
        "id": "c80e4519"
      },
      "outputs": [],
      "source": [
        "print(len(x_train_try1))\n",
        "print(len(y_train_try1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This first round of model selection takes into account **3 hyperparameters**: the **number of convolutional layers**, the **number of dense layers** and the **size of the layers**. Having already tried some models singularly taken I know that a layer size larger than 128 would take really long time to train. Furthermore, 0, 1 and 2 for the  number of dense layers and 1, 2 and 3 for the  number of convolutional layers seem reasonable choices."
      ],
      "metadata": {
        "id": "zxp_uYM4F56c"
      },
      "id": "zxp_uYM4F56c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c75d6e4",
      "metadata": {
        "id": "8c75d6e4"
      },
      "outputs": [],
      "source": [
        "dense_layers = [0, 1, 2]\n",
        "layer_sizes = [32, 64, 128]\n",
        "conv_layers = [1, 2, 3]\n",
        "\n",
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "            print(NAME)\n",
        "\n",
        "            model = Sequential()\n",
        "\n",
        "            model.add(Conv2D(layer_size, (3, 3), input_shape=x_train_try1.shape[1:]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "                model.add(Conv2D(layer_size, (3, 3)))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            model.add(Flatten())\n",
        "\n",
        "            for _ in range(dense_layer):\n",
        "                model.add(Dense(layer_size))\n",
        "                model.add(Activation('relu'))\n",
        "\n",
        "            model.add(Dense(1))\n",
        "            model.add(Activation('sigmoid'))\n",
        "\n",
        "            tensorboard = TensorBoard(log_dir=\"logs_opt/{}\".format(NAME))\n",
        "\n",
        "            model.compile(loss='binary_crossentropy',\n",
        "                          optimizer='adam',\n",
        "                          metrics=['accuracy'],\n",
        "                          )\n",
        "\n",
        "            model.fit(x_train_try1, y_train_try1,\n",
        "                      batch_size=32,\n",
        "                      epochs=10,\n",
        "                      validation_split=0.3,\n",
        "                      callbacks=[tensorboard])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the next line we can display the performances of our models with tensorboard inline."
      ],
      "metadata": {
        "id": "ASNUHLvx_9hm"
      },
      "id": "ASNUHLvx_9hm"
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_opt"
      ],
      "metadata": {
        "id": "a5jhPQJZSF1v"
      },
      "id": "a5jhPQJZSF1v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**First round considerations**:\n",
        "Looking at the best 8 models in terms of validation loss we can draw some considerations.\n",
        "\n",
        "1.   Models without any dense layer are completely instable\n",
        "2.   Models with only 1 convolutional layer have bad performances and models with 3 convolutional layers are definitely the best\n",
        "3.   Models with 128 as layer sizes have very large training duration without too much improvement\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pgJmp2yKH2Jb"
      },
      "id": "pgJmp2yKH2Jb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**6) Second round of model selection**\n",
        "In this round I increased the portion of the training set (**10.400 images**) used to perform Grid Search.\n",
        "Larger number of observations (*n*) increase the training duration. However it is needed to see if modifing *n* also the models ranking would vary."
      ],
      "metadata": {
        "id": "VtuN8GkqJEV4"
      },
      "id": "VtuN8GkqJEV4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af60c14",
      "metadata": {
        "id": "6af60c14"
      },
      "outputs": [],
      "source": [
        "x_train_try2, x_train_notused2, y_train_try2, y_train_notused2 = train_test_split(x_train,y_train,test_size=0.35)\n",
        "print(len(x_train_try2))\n",
        "print(len(y_train_try2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the Grid Search is performed on a smaller number of models based on previous conclusions.\n",
        "The number of convolutional layers is fixed to 3 and I also excluded models with 0 dense layers.\n"
      ],
      "metadata": {
        "id": "mGHfUsadKKeK"
      },
      "id": "mGHfUsadKKeK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c01acb",
      "metadata": {
        "id": "c7c01acb"
      },
      "outputs": [],
      "source": [
        "dense_layers = [1, 2]\n",
        "layer_sizes = [32, 64, 128]\n",
        "conv_layers = [3]\n",
        "\n",
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
        "            print(NAME)\n",
        "\n",
        "            model = Sequential()\n",
        "\n",
        "            model.add(Conv2D(layer_size, (3, 3), input_shape=x_train_try2.shape[1:]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "                model.add(Conv2D(layer_size, (3, 3)))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            model.add(Flatten())\n",
        "\n",
        "            for _ in range(dense_layer):\n",
        "                model.add(Dense(layer_size))\n",
        "                model.add(Activation('relu'))\n",
        "\n",
        "            model.add(Dense(1))\n",
        "            model.add(Activation('sigmoid'))\n",
        "\n",
        "            tensorboard = TensorBoard(log_dir=\"logs_opt_2r/{}\".format(NAME))\n",
        "\n",
        "            model.compile(loss='binary_crossentropy',\n",
        "                          optimizer='adam',\n",
        "                          metrics=['accuracy'],\n",
        "                          )\n",
        "\n",
        "            model.fit(x_train_try2, y_train_try2,\n",
        "                      batch_size=32,\n",
        "                      epochs=8,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[tensorboard])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_opt_2r"
      ],
      "metadata": {
        "id": "tfOxc4hSSOHT"
      },
      "id": "tfOxc4hSSOHT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Second round considerations**:\n",
        "Not including models with zero dense layer was definitely a good choice: all the models are now stable.\n",
        "\n",
        "The best 4 models in terms of validation loss are:\n",
        "\n",
        "1.   3 Convolutional Layers, Layer sizes 128 and 1 dense layer. Very large training duration: 1h, 34 min and 18 sec\n",
        "2.   3 Convolutional Layers, Layer sizes 64 and 2 dense layer. Quick training duration: 18 min and 25 sec\n",
        "3.   3 Convolutional Layers, Layer sizes 128 and 2 dense layer. Large training duration: 1h, 5 min and 33 sec\n",
        "4.   3 Convolutional Layers, Layer sizes 32 and 1 dense layer. Definitely the most quick for training: 6 min and 36 sec\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wETnw_igK8j7"
      },
      "id": "wETnw_igK8j7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7) Final training of the best models**\n",
        "Now its time to train this 4 models with the entire training set (**16.000 images**) for the final evaluation."
      ],
      "metadata": {
        "id": "3zcJ17wbQJ50"
      },
      "id": "3zcJ17wbQJ50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c203813",
      "metadata": {
        "id": "1c203813"
      },
      "outputs": [],
      "source": [
        "\n",
        "NAME = \"faces-3-32-1-{}\".format(int(time.time()))\n",
        "\n",
        "model1 = Sequential()\n",
        "\n",
        "model1.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model1.add(Conv2D(32, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model1.add(Conv2D(32, (3, 3)))\n",
        "model1.add(Activation('relu'))\n",
        "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model1.add(Flatten())\n",
        "\n",
        "\n",
        "model1.add(Dense(32))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "model1.add(Dense(1))\n",
        "model1.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_finalmodels/{}\".format(NAME))\n",
        "\n",
        "model1.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model1.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model1.save('faces3-32-1.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4d56f7",
      "metadata": {
        "id": "cb4d56f7"
      },
      "outputs": [],
      "source": [
        "NAME = \"faces-3-64-2-{}\".format(int(time.time()))\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "\n",
        "model2.add(Dense(64))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "model2.add(Dense(64))\n",
        "model2.add(Activation('relu'))\n",
        "\n",
        "model2.add(Dense(1))\n",
        "model2.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_finalmodels/{}\".format(NAME))\n",
        "\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model2.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model2.save('faces3-64-2.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f0ea52",
      "metadata": {
        "id": "d9f0ea52"
      },
      "outputs": [],
      "source": [
        "NAME = \"faces-3-128-1-{}\".format(int(time.time()))\n",
        "\n",
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv2D(128, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Conv2D(128, (3, 3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Conv2D(128, (3, 3)))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model3.add(Flatten())\n",
        "\n",
        "model3.add(Dense(128))\n",
        "model3.add(Activation('relu'))\n",
        "\n",
        "model3.add(Dense(1))\n",
        "model3.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_finalmodels/{}\".format(NAME))\n",
        "\n",
        "model3.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model3.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model3.save('faces3-128-1.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb31e8f1",
      "metadata": {
        "id": "bb31e8f1"
      },
      "outputs": [],
      "source": [
        "NAME = \"faces-3-128-2-{}\".format(int(time.time()))\n",
        "\n",
        "model4 = Sequential()\n",
        "\n",
        "model4.add(Conv2D(128, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model4.add(Conv2D(128, (3, 3)))\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model4.add(Conv2D(128, (3, 3)))\n",
        "model4.add(Activation('relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model4.add(Flatten())\n",
        "\n",
        "\n",
        "model4.add(Dense(128))\n",
        "model4.add(Activation('relu'))\n",
        "\n",
        "model4.add(Dense(128))\n",
        "model4.add(Activation('relu'))\n",
        "\n",
        "model4.add(Dense(1))\n",
        "model4.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_finalmodels/{}\".format(NAME))\n",
        "\n",
        "model4.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model4.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model4.save('faces3-128-2.model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_train_finalmodels"
      ],
      "metadata": {
        "id": "HsG1d2Dsc-PI"
      },
      "id": "HsG1d2Dsc-PI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**8) Can we further improve our models?**\n",
        "Definitely with **larger dataset** we could have improved our trained models. However we don't have it.<br><br>\n",
        "Instead, something we could have definitely done is a deeper hyperparameters tuning.<br>\n",
        "I have only perform model selection on few hyperparameter values. For this project we don't have neither the computational capacity nor the time to perform a larger Grid Search.<br>\n",
        "However based on what we learned from previous steps there is something we can try.<br><br>\n",
        "We know that the **layer sizes** can not be enlarge for time resources and it seemed not to imporve too much performances.<br>\n",
        "Excluding the case with zero **dense layers**, this hyperparameter value alone seemed not to change the performances.<br>\n",
        "The **number of convolutional layers** instead could definitely be a leading factor in model performances.<br> <br>\n",
        "We can try our best performing model (among the quick ones) with 4 or 5 convolutional layers!"
      ],
      "metadata": {
        "id": "CwzHpbniWVvV"
      },
      "id": "CwzHpbniWVvV"
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"faces-4-64-2-{}\".format(int(time.time()))\n",
        "\n",
        "model5 = Sequential()\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3)))\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3)))\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model5.add(Conv2D(64, (3, 3)))\n",
        "model5.add(Activation('relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model5.add(Flatten())\n",
        "\n",
        "\n",
        "model5.add(Dense(64))\n",
        "model5.add(Activation('relu'))\n",
        "\n",
        "model5.add(Dense(64))\n",
        "model5.add(Activation('relu'))\n",
        "\n",
        "model5.add(Dense(1))\n",
        "model5.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_manyconv/{}\".format(NAME))\n",
        "\n",
        "model5.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model5.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model5.save('faces4-64-2.model')"
      ],
      "metadata": {
        "id": "3pguvsyUZxS5"
      },
      "id": "3pguvsyUZxS5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"faces-5-64-2-{}\".format(int(time.time()))\n",
        "\n",
        "model6 = Sequential()\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3)))\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3)))\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3)))\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model6.add(Conv2D(64, (3, 3)))\n",
        "model6.add(Activation('relu'))\n",
        "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model6.add(Flatten())\n",
        "\n",
        "\n",
        "model6.add(Dense(64))\n",
        "model6.add(Activation('relu'))\n",
        "\n",
        "model6.add(Dense(64))\n",
        "model6.add(Activation('relu'))\n",
        "\n",
        "model6.add(Dense(1))\n",
        "model6.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_manyconv/{}\".format(NAME))\n",
        "\n",
        "model6.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model6.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model6.save('faces5-64-2.model')"
      ],
      "metadata": {
        "id": "UBnC1P0JZxKj"
      },
      "id": "UBnC1P0JZxKj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs_train_manyconv"
      ],
      "metadata": {
        "id": "Ty1vyJTrbkTC"
      },
      "id": "Ty1vyJTrbkTC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It definitely seems that the models with 4 and 5 convolutional layers perform better.<br><br>\n",
        "The last attempt I want to do is to see if reducing the layers sizes of the model with 5 convolutional layers would reduce the training duration without worsening the accuracy"
      ],
      "metadata": {
        "id": "91t282UjjVY4"
      },
      "id": "91t282UjjVY4"
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"faces-5-32-2-{}\".format(int(time.time()))\n",
        "\n",
        "model7 = Sequential()\n",
        "\n",
        "model7.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model7.add(Conv2D(32, (3, 3)))\n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model7.add(Conv2D(32, (3, 3)))\n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model7.add(Conv2D(32, (3, 3)))\n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model7.add(Conv2D(32, (3, 3)))\n",
        "model7.add(Activation('relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model7.add(Flatten())\n",
        "\n",
        "\n",
        "model7.add(Dense(32))\n",
        "model7.add(Activation('relu'))\n",
        "\n",
        "model7.add(Dense(32))\n",
        "model7.add(Activation('relu'))\n",
        "\n",
        "model7.add(Dense(1))\n",
        "model7.add(Activation('sigmoid'))\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"logs_train_manyconv/{}\".format(NAME))\n",
        "\n",
        "model7.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        "\n",
        "model7.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[tensorboard])\n",
        "\n",
        "model7.save('faces5-32-2.model')"
      ],
      "metadata": {
        "id": "d7sA4K0CjTNs"
      },
      "id": "d7sA4K0CjTNs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes. The model with 5 convolutional layers, 2 dense layers and 32 as layers sizes is much faster loosing only very little validation accuracy.\n",
        "\n",
        "We definitely have to include this 3 models in the testing part."
      ],
      "metadata": {
        "id": "3rxvdo79kLnl"
      },
      "id": "3rxvdo79kLnl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**In conclusion**\n",
        "Larger numebr of convolutional layers could be tested<br>\n",
        "Other technologies could have been added to try to improve the performances.<br>\n",
        "A typical choice for this kind of models is to add a **Drop Out Layer**. It is used to prevent overfitting from happening. I didn't include it because definitely I had no overfitting issues."
      ],
      "metadata": {
        "id": "AkWJOpfFbmO5"
      },
      "id": "AkWJOpfFbmO5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The next cell can be used to connect your Google Drive account with Google colab. It is very useful to save your trained models because when the Colab Runtime is stopped you lose all your variables and models.*"
      ],
      "metadata": {
        "id": "P2ZlCpOdQnPV"
      },
      "id": "P2ZlCpOdQnPV"
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "KWSJjU9LTzPR"
      },
      "id": "KWSJjU9LTzPR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9) Testing final models**\n",
        "Now it's time to use the test set (**4.000 images**) to evaluate the performance of our final models.\n",
        "For each model I displayed **test loss**, **test accuracy** and the **confusion matrix**\n",
        "To interpret the confusion matri: 0 correspond to real faces and 1 to comics faces"
      ],
      "metadata": {
        "id": "XXKS-UWfRGhh"
      },
      "id": "XXKS-UWfRGhh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**4conv-64size-2dense Model test performances**"
      ],
      "metadata": {
        "id": "vT6NzwhuapSZ"
      },
      "id": "vT6NzwhuapSZ"
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = tf.keras.models.load_model(\"faces4-64-2.model\")\n",
        "\n",
        "results5 = model5.evaluate(x_test, y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results5)"
      ],
      "metadata": {
        "id": "v2wUaSzHarc8"
      },
      "id": "v2wUaSzHarc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod5_pred=model5.predict(x_test)\n",
        "mod5_prediction=np.around(mod5_pred,1)"
      ],
      "metadata": {
        "id": "-1WCmqIZarUM"
      },
      "id": "-1WCmqIZarUM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm5=tf.math.confusion_matrix(\n",
        "    y_test,\n",
        "    mod5_prediction)\n",
        "plt.figure(figsize = (5,4))\n",
        "sn.heatmap(cm5, annot=True, annot_kws={\"size\": 16},cmap='Blues')"
      ],
      "metadata": {
        "id": "bjINKQTRarMM"
      },
      "id": "bjINKQTRarMM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**5conv-64size-2dense Model test performances**"
      ],
      "metadata": {
        "id": "ejRkLpuaatpT"
      },
      "id": "ejRkLpuaatpT"
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = tf.keras.models.load_model(\"faces5-64-2.model\")\n",
        "\n",
        "results6 = model6.evaluate(x_test, y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results6)"
      ],
      "metadata": {
        "id": "lFtzNdvoataN"
      },
      "id": "lFtzNdvoataN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod6_pred=model6.predict(x_test)\n",
        "mod6_prediction=np.around(mod6_pred,1)"
      ],
      "metadata": {
        "id": "L00v_ZOVatRx"
      },
      "id": "L00v_ZOVatRx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm6=tf.math.confusion_matrix(\n",
        "    y_test,\n",
        "    mod6_prediction)\n",
        "plt.figure(figsize = (5,4))\n",
        "sn.heatmap(cm6, annot=True, annot_kws={\"size\": 16},cmap='Blues')"
      ],
      "metadata": {
        "id": "J3HrPzE_atIG"
      },
      "id": "J3HrPzE_atIG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**5conv-32size-2dense Model test performances**"
      ],
      "metadata": {
        "id": "YYBf1iK7lh_m"
      },
      "id": "YYBf1iK7lh_m"
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = tf.keras.models.load_model(\"faces5-32-2.model\")\n",
        "\n",
        "results7 = model7.evaluate(x_test, y_test, batch_size=128)\n",
        "print(\"test loss, test acc:\", results7)"
      ],
      "metadata": {
        "id": "bgl-qraxlhtq"
      },
      "id": "bgl-qraxlhtq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mod7_pred=model7.predict(x_test)\n",
        "mod7_prediction=np.around(mod7_pred,1)"
      ],
      "metadata": {
        "id": "frJJQTFelhpg"
      },
      "id": "frJJQTFelhpg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm7=tf.math.confusion_matrix(\n",
        "    y_test,\n",
        "    mod7_prediction)\n",
        "plt.figure(figsize = (5,4))\n",
        "sn.heatmap(cm7, annot=True, annot_kws={\"size\": 16},cmap='Blues')"
      ],
      "metadata": {
        "id": "_P4rCQ5_lhlv"
      },
      "id": "_P4rCQ5_lhlv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Project_AMD_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}